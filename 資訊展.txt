https://hackmd.io/@william0405/information




1.holo defender:我覺得很厲害，他的流程圖帶給我的理解是這個系統可以在偵測到出現危險的武器或是奇怪行為時，就會開始錄影跟發出簡訊通知給使用者做警告，但我在看了幾次後發現好像是監視器平常都是錄影著的，而平常就會把串流片段進行切割保存，那當偵測到異常時才會把危險的片段擷取下來儲存到儲存裝置中(可能要拿去跟串流片段做比較就能知道發生的時間點?)，代表平時ai模型要一直偵測及時的影像，我目前的想法只有覺得這樣儲存裝置會不會爆掉? 感覺沒有說明儲存裝置會不會過可能多少時間自動清理空間之類的。
(oc-sort應該是一種排序演算法，但我不知為何會需要用到?可能是因為東西越危險的要排越前面辨識嗎?)

2.機械手臂自動化上架:很厲害，做了很多面向的東西，除了硬體機器人的材料選擇外，他們選擇的Mask R-CNN套件也是比之前的fast R-CNN還厲害，aruco也能讓他們快速地掃出資料，我覺得最難也是當初沒想到的應該是他們最後的步驟，要取得感測的數據輸入到...中進行地圖構建跟同時又要使用演算法算出全域路徑及局部路徑的最佳路徑及最佳速度，使不會在移動時互相碰撞。
我覺得我目前的想法只有好奇他們是怎麼偵測貨架上商品的數量的，假如是用掃code方式 掃一次代表減一次?或是商品上都必須要有aruco能辨識數量的小code之類的? 還有我覺得是不是這邊只能一次夾取一個瓶子，感覺爪子不是很大，如果想要抓東西抓穩一點的話可以參考我英文報告裡有查到的用摺紙的應用設計出的3d列印的抓手，可以輕鬆抓取超過自身100重量的物品。

3.整合exergaming技術:我覺得這是一個對人體有益的研究，他們用了openpose結合unity，不過我蠻好奇他們是怎麼設計你的動作有沒有正確的，而且聽組員、組長說他們架的兩個攝影機分別拍正面跟側面，那在設計動作對應的正確pose時代表正面跟側面都需要去設計，我目前想到的是1.在當時要做的動作時的某一個部位可能會需要大幅度的彎曲，所以可以透過當下如果該部位檢測到的數值叫大及代表你的動作做的正確，2.需要先進行模型的訓練 訓練對應的動作的模型偵測，但可能需要拍攝大量照片(含側面跟正面)，用對應動做的模型去檢測是不是當下做的動作是否正確。

4.工地安全管理系統:我看完了介紹圖後我的第一個想法是我覺得他們做的這個系統感覺沒辦法增加太多工人在工地上的安全，他們做了裝備的佩帶辨識、工人定位、人臉辨識且用資料庫配合網頁呈現出來，但在工地上真的會有一個負責監督的人開著電腦整天看著網頁監督大家的安全嗎? 就算有 可是工地上會發生意外很多都是突如其來的，該怎麼防範? 我覺得這個不算是安全系統，感覺很像監督工人是否有正確配戴裝置及出缺席點名系統，且裡面提及的定位系統 如果真的有人發生意外，假如是腳被重物壓到， 那應該是不是需要有一個裝置是可以讓大家馬上知道你這邊出了狀況的，配合上定位系統確實可以達到即時救援。

5.vr/xr沉浸式串珠:想看串出一個成品! 但我這次沒去看學姊他們的攤位，我突然想到之前菁惠老師有說他們的教學模擬系統好像有點奇怪?

6.線上教學助手學習平台:我覺得這個是可以讓學生跟教學者都能進步的平台，我覺得大概是資料庫結合前端的網頁設計出來的專題，裡面應該有用到不同的函式庫之類的? 對這組沒太多太別的想法

7.先進電晶體特性量測:我覺得困難，很多名詞看不懂，在硬體的世界我不理解...，好像是在做電晶體的性能評估測試嗎?

8.過敏識食:我覺得這是一個很有意義的專題，流程圖看的不清楚，其中我想知道食物影像辨識技術是他們自己訓練的model還是找已經訓練好的? 還是就是用yolo 來做的?裡面的部份我覺得比較困難的地方在於食物排除法模組，他是說協助醫生制定患者的食物排除療程，但我覺得有點模糊的是它是做找到對食物過敏原後就把相關的食物去除掉，還是是相反的把該食物留下來，哪個對協助醫生的判斷幫助較快?我覺得是後者，這樣就能直接制定患者不要吃什麼去做規劃嗎? 最後我覺得他們也有把他們的團隊開發流程講出來，不愧是資管系的，在管理方面相當的注重!!

9.彩繪社區:感覺他們可以加些使用到的技術在看板上。

10.機械手臂及灑水功能飛行探測器:蠻有趣的，這組用無人機，兩個攤位在一起，第九組做專題也有用到空拍機?。看完後我覺得蠻有意思的，如果這些機器都是他們從頭組裝出來的真的很厲害，感受得到他們想做多功能的無人機，但有個問題是動機是幫助農民灑水跟幫助消防員救火，可是感覺灑水幫浦的水容量跟水壓應該不足吧? 但我覺得很有趣，讓我想到未來說不定都是由無人機來做外送，或許朝那方向研究專題也很有趣。

11.應用於圖書館導引服務之智慧型機器人系統開發:我第一個覺得的問題是要是書籍沒有按照資料庫的位置正確擺放在書架上，是不是會導致錯誤?   我覺得他們結合了很多東西，1.爬蟲爬書籍比對資料庫 2.演算法找路徑最佳化 3.用react.js與flask使用似服器同時管理管理多個機器人 ，我覺得蠻有趣的 ，我一開始以為只有一台機器人 沒想到他們做的是可以對多台機器人的管理。

12.救護e聯盟:我覺得這個有點扯，感覺很像是在做一個平台建置的練習， 第一個我覺得非常不合理的地方是為什麼傷患要透過網址發送請求? 假如 我已經摔到手都殘廢了，該怎麼發出網址? 第二個很扯的點是為什麼救護員可以選擇要不要接單?? 這又不是外送平台，救護員的職責不就是救人ㄇ???有人受傷就去幫忙阿，還可以選擇要不要幫我覺得超怪的，感覺很不尊重這個職業，看的很生氣，沒什麼其他特別的想法。

13.深度學習法院判決:在攤位看過去時感覺是很難的東西，在回家看圖片的看板時，我的想法是如果他們是去訓練三個模型來做這個專題的話，感覺比較困難的會是相似判決書的部分。我對機器學習不熟 但我覺得上面的風險詞標記跟案件對應的罰金預測結果感覺不會太困難嗎?在網路上把查到的資料拿去訓練模型 對應的key value是不是就能訓練出來之類的?

14.瓦斯表:沒什麼特別想法 ，之前看過了，覺得比較有趣的是結合line bot，比較想知道line bot的部分是他們在接openAi apk的過程有沒有特別設計甚麼之類的，還是單純他們只是用line官方帳號的自動 AI 回覆那些功能。

15.四弦翼飛行器目標偵測與自動飛行任務實現:我覺得這組很厲害，感覺就偶是需要花很多時間做的，語音辨識、姿態辨識、路徑規劃等等，很多不同的技術要做處理，他們的重點好像不是放在組裝機器需要用哪些零件上，而是著重在我要用這個機器可以同時使用到多少技術，因為圖片我拍得很模糊的關係我覺得單看看板完全不太懂在幹嘛，說是設計物流派遣視窗畫面，我猜語音跟姿態是遠端操控的部分，但我不知道這邊用openCV影像偵測做即時錄影的目的是什麼，我覺得這組的題目給我的感覺也很像賈院長的瓦斯表，有可能是業界的人士來拜託做的專案之類的?(物流派遣)

16.送餐機器人:我覺得他們把步驟寫的蠻詳細的，感覺可以拆成好幾個部份去實作，1.建構出餐廳地圖跟做機器人的碰撞雷射判斷2.研究機器人如何自主導航移動 3.手機掃qr code下指令與機器人的通訊連接，我覺得這個題目蠻有趣的，看到餐廳的機器人都很好奇是怎麼做出來的，現在看到他們使用到的技術跟流程大概有個概念了!

17.具有身分識別英語會話教育機器人:之前有在s6的研討室看過她們的作品，我覺得身份辨識那邊感覺是最難做的地方，等於你除了要能正確的辨識使用者聲音外，還要確定能去抓到使用者聲音對應在裡面做練習的紀錄，假如今天有兩個人聲音很像，會不會就很難辨識出來，第二個我想知道的是自由對談模式是不是直接串接到gpt跟gpt做語音的互動?(現在手機的gpt可以用語音，電腦的我不確定)

18.骨架偵測技術 居家健身訓練系統:透過看板大概了解了使用的流程，覺得蠻容易讓人理解的，也了解到這種做健身的偵測她們是用提取的特徵點做角度計算的，所以只要及時的捕捉使用者的關鍵點並做角度計算，角度有在該動作正確的範圍內，代表動作是正確的，但我覺得在過程會遇到的問題是如果某些動作很類似的話是不是比較難偵測辨識。(前面登入是用人臉辨識登入我覺得蠻不錯的，很方便)

19.醫手包辦:在看到這是有得獎的作品就覺得不簡單，看了看版的內容後覺得這是一個很有意義且對社會貢獻很大的專題，我覺得裡面最困難的部分一看就知道是手語辨識，且看他們的文字說明這個手語辨識模型還是她們自己訓練出來的，真的好厲害!!代表他們在訓練模型前還要做不少關於手語的學習，看得出付出了很多時間。

20.這組我沒拍到看板，但看題目應該是用深度學習對電動車的電池做診斷，感覺很深奧!

21.基於手臂關節姿態估測之教導型機器人:看不懂，我的理解是用4個穿戴式裝置控制機械手臂的動作，但我不太懂這能做到教導甚麼? 為什麼還要特別用機器人手呈現教導的功能，直接自己示範不就好了嗎?

22.moodster:感覺蠻商業化的一個專題，裡面比較需要花時間的部分就是需要訓練模型時要把圖片上對應的情緒上label，有七種所以要分七類，可是裡面好像沒提到人臉辨識是用什麼模型?該不會人臉辨識系統是她們自己訓練的吧?是的話 那我覺得也是個大工程呢!!

23.電腦視覺自動收鞋:看完她們的看板內容後，覺得他們做的內容結合了很多技術，而且又要結合機器人，是個大工程，機器人的設計跟設備的選材應該也是她們自己研究的，感覺需要花很多時間才能完成，其中流程有看到熟悉的用open cv做人臉對其為正臉，然後她們又用了其他模型跟areface做讓特徵更明顯來藉此辨識使用者身分，然後又用v8做分割等等。她們做了對使用者動向偵測的進入跟離開，可是好像沒描述怎樣動向算是進入 怎樣動向算是離開，蠻模糊的，還有一個模糊的地方是機器人收鞋對應到鞋櫃的編號， 機器人是怎麼知道真實世界所對應的鞋櫃編號的?，是用深度相機掃描到數字還是qr code之類的所以能知道要放到哪個對應的鞋櫃嗎?這部分好像沒特別說明，總體我覺得超厲害，講了很多做的流程跟運用了很多技術。

24.兒童早療遊戲是肢體訓練:看板很淺顯易懂，感覺這組做的不是很困難，發現她們好像沒描述輔助治療的動作有哪些之類的，也沒說是怎麼判斷使用者動作是不是正確的，但我發現到人體支點模型好像有幾組都是使用mediapipe，然後網頁做的很好看，而且她們做的能在不同裝置上跑(因為是網頁?)，很方便。

25.應用於平板的5g mimo天線設計與開發:記得這個得很多獎，我看不懂，只知道無線網路大葉老師講過MIMO，結合現在很新的WIFI6E的多天線，看不懂我也不知道天線怎麼接多調配置，完全沒想法。

26.AI電腦視覺輔助即時車位:看完看板介紹後我發現kaggle、yolo v8有不少人在用，但我還是不知道她們偵測停車場時假如遇到柱子或摘擋住相機視野該怎麼辦? 且停車場很大的話是要架很多台攝影機嗎?

27.taipei tour gpt:看板沒看到老師名字但我猜是余人彭老師帶的組，之前有看到的這位老師的某個專案是可以地理老師上課的系統，我覺得這個有點像，主要就是都跟地理有關。她們先將文字做預處理在導入自己做的系統，還會將產生的結果做修正。整體覺得很不錯，視覺化的介面也很好看，感覺最難的部分適性化行程編輯模組，能新增、刪除、修改的同時要對地圖上的資訊做跟改，不過很好奇她是會依照距離越近的兩個點來做行程的規劃嗎(即ai可以自動該更改行程排序)? 還是單純依照使用者更改排的順序做變更?

28.網頁智慧點銘:這組我有體驗掃她們的qrcode，但我如果用學校的帳號她們會出點問題，用自己的就正常，主要好像是點進去後會創建id儲存到後端資料庫，然後點名系統就會自動把打勾刪除掉(她們好像預設是好像先把全部人都打勾記缺席)，每堂課都會有一個qr code，突然我想到巧汶老師上課都是用moodle開點名區做加分，但這個掃碼應該是直接把學生資訊系統的點名資料做更改，時間一到就自動上傳名單。

29.物聯網毛孩:感覺做了很多技術的使用，硬體arduino 軟體做app app又能控制紅外線光，我不太懂為什麼距離感測器大於多少時就要開始餵食，也不懂攝影機採集影像跟溫濕度感測的目的是為了甚麼，雷射逗貓感覺也有點牽強? 感覺很像是大雜燴的感覺，有點奇怪。
